[
  {
    "objectID": "src/mlops/index.html",
    "href": "src/mlops/index.html",
    "title": "SSP Cloud Datalab",
    "section": "",
    "text": "TOTO",
    "crumbs": [
      "4 - MLOps"
    ]
  },
  {
    "objectID": "src/principles/index.html",
    "href": "src/principles/index.html",
    "title": "SSP Cloud Datalab",
    "section": "",
    "text": "TOTO",
    "crumbs": [
      "2 - Principes"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Un beau titre en francais",
    "section": "",
    "text": "Un beau titre en francais\n\nRésumé\nToto"
  },
  {
    "objectID": "src/introduction/index.html",
    "href": "src/introduction/index.html",
    "title": "SSP Cloud Datalab",
    "section": "",
    "text": "0.1 Introduction\nL’exploitation de sources de données non traditionnelles afin d’améliorer le processus de production statistique est une orientation majeure du Système Statistique Européen (SSE), résumée à travers le concept de Trusted Smart Statistics (Ricciato et al. (2019)). Cette dynamique s’accompagne d’innovations dans les processus statistiques, permettant de tirer parti du potentiel de ces sources — plus grande disponibilité, résolution spatio-temporelle accrue, etc. — tout en faisant face à leur complexité et à leurs limites. Parmi ces innovations figurent les méthodes d’apprentissage automatique et leurs applications prometteuses dans les domaines du codage et de la classification, des redressements et de l’imputation (Gjaltema (2022)). Les multiples défis auxquels font face les instituts statistiques dans ce contexte d’évolution sont abordés dans le Mémorandum de Bucarest sur les statistiques officielles dans une société numérisée, qui prévoit que “la variété des nouvelles sources de données, paradigmes computationnels et outils nécessitera des adaptations de l’architecture métier statistique, des processus, des modèles de production, des infrastructures informatiques, des cadres méthodologiques et de qualité, ainsi que des structures de gouvernance correspondantes”, et invite en conséquence le SSE à évaluer les adaptations requises et à les prioriser (DGINS (2018)). L’orientation B (“innover et être en première ligne sur les sources de données”) de la stratégie Insee Horizon 2025 traduit l’opérationnalisation de cette orientation dans le cadre du service statistique public (INSEE (2016)).\nDans l’optique de ces transformations, de nombreux travaux ont été menés dans le cadre de projets successifs à l’échelle européenne pour opérationnaliser l’utilisation de sources de données non-traditionnelles dans la production de statistiques officielles. Dans le cadre du projet ESSnet Big Data II (2018-2020), les instituts statistiques nationaux (INS) ont travaillé sur une large gamme de thématiques (offres d’emploi en ligne, transactions financières, traces GPS, etc.) afin de constituer les briques nécessaires pour intégrer ces sources dans les processus de production et identifier leurs limites (EUROSTAT (2021)). En France, les travaux sur l’exploitation des données mobiles (Sakarovitch et al. (2018)) ou des données de caisse (Leclair et al. (2019)) ont permis d’illustrer le potentiel de ces sources pour construire de nouveaux indicateurs ou raffiner des indicateurs existants. Néanmoins, si un travail considérable a été consacré au développement de cadres méthodologiques (Descy et al. (2019), Salgado et al. (2020)), de lignes directrices sur la qualité (Kowarik and Six (2022)), ainsi qu’à la conception de processus sécurisant l’acquisition de données auprès de tiers (Ricciato et al. (2018)), les infrastructures informatiques et les compétences nécessaires pour gérer ces nouveaux objets sont restées peu abordées dans la littérature.\nLes caractéristiques de ces nouvelles sources rendent leur traitement particulièrement complexe. On qualifie souvent de big data ces données qui se distinguent par leur volume (souvent de l’ordre de plusieurs centaines de Go voire du To), leur vélocité (vitesse de génération, proche du temps réel) ou de leur variété (données structurées mais aussi non structurées, telles que les textes et les images). Pourtant, les “compétences pour automatiser, analyser et optimiser ces systèmes complexes ne font souvent pas partie des compétences traditionnelles de la plupart des instituts statistiques nationaux” (Ashofteh and Bravo (2021)). Malgré tout, on observe au cours des dernières années un nombre croissant de statisticiens publics formés aux méthodes de data science, permettant d’envisager l’intégration de ces sources dans des processus de production statistique. Dans ses multiples acceptions, le terme “data scientist” reflète en effet l’implication croissante des statisticiens dans le développement informatique et l’orchestration de leurs opérations de traitement des données, au-delà des seules phases de conception ou de validation (Davenport and Patil (2012)). Toutefois, on observe en pratique, à l’Insee et dans d’autres organisations, que la capacité de ces profils à tirer parti des sources big data et des méthodes d’apprentissage automatique est limitée par plusieurs défis.\nUn premier défi réside dans l’absence d’infrastructures informatiques adaptées aux nouvelles sources de données auxquelles les INS ont désormais accès, ainsi qu’au besoin croissant de nouvelles méthodes statistiques. Par exemple, les sources big data nécessitent d’énormes capacités de stockage et s’appuient souvent sur des infrastructures et des méthodes de calcul distribué pour être traitées (Liu (2013)). De même, l’adoption de nouvelles méthodes statistiques basées sur des algorithmes d’apprentissage automatique requiert des capacités informatiques — en particulier des GPU (unités de traitement graphique) dans le cadre du traitement du texte ou de l’image — pour paralléliser massivement les calculs (Saiyeda and Mir (2017)). De telles ressources sont rarement disponibles dans les infrastructures informatiques traditionnelles. Lorsque des infrastructures de calcul adaptées sont disponibles, comme les supercalculateurs (HPC) utilisés dans certains domaines de recherche, elles nécessitent des compétences spécifiques — notamment pour leur mise en place et leur maintenance — qui sont rarement disponibles au sein des INS.\nUn autre défi majeur pour les statisticiens est de disposer d’environnements de développement leur permettant d’expérimenter plus librement. L’essence de l’innovation dans les travaux statistiques réside dans la capacité à intégrer rapidement de nouveaux outils et méthodologies. Cette agilité est limitée lorsque les statisticiens dépendent excessivement des départements informatiques pour provisionner des ressources ou installer de nouveaux logiciels. Dans les configurations traditionnelles — ordinateurs personnels ou bureaux virtuels sur des architectures centralisées1 — les départements informatiques privilégient généralement la sécurité et la stabilité du système au détriment de la fourniture de nouveaux services, ce qui limite le potentiel d’innovation. De plus, ces environnements rigides rendent difficile la mise en œuvre de bonnes pratiques de développement, telles que le travail collaboratif — nécessitant des environnements permettant de partager facilement des expérimentations avec ses pairs — et la reproductibilité.\n1 AUSv3 est un exemple d’une telle infrastructure. Le statisticien utilise son poste de travail comme point d’accès à un bureau virtuel qui “reproduit” l’expérience habituelle du poste de travail. Néanmoins, les calculs qui sont lancés — via R ou Python par exemple — sont effectués sur des machines virtuelles (VM) de calcul dédiées, et non sur le poste de travail.Un troisième défi concerne la difficulté de passer des expérimentations innovantes à des solutions en production. Même lorsque les statisticiens ont accès à des environnements leur permettant d’expérimenter aisément, la transition vers le déploiement d’une application ou d’un modèle reste généralement difficile. Les environnements de production diffèrent souvent des environnements de développement, ce qui entraîne des coûts de développement supplémentaires importants pour passer d’une preuve de concept à une solution industrialisée qui rend du service dans la durée. Par exemple, dans le cas des projets d’apprentissage automatique, les modèles déployés nécessitent un suivi rigoureux pour s’assurer qu’ils conservent leur précision et leur utilité au fil du temps, et requièrent généralement des améliorations périodiques ou continues. Ces besoins plaident pour des environnements plus flexibles permettant aux statisticiens de gérer de manière autonome le cycle de vie complet de leurs projets de data science.\nCes différents défis ont un thème sous-jacent commun : le besoin d’une plus grande autonomie. La capacité des méthodes de data science à améliorer et potentiellement transformer la production des statistiques officielles dépend crucialement de la capacité des statisticiens à mener des expérimentations innovantes plus librement. Pour ce faire, ils doivent avoir accès à des ressources informatiques substantielles et diversifiées leur permettant de gérer le volume et la diversité des sources big data et d’exploiter les méthodes d’apprentissage automatique. Ces projets expérimentaux nécessitent à leur tour des environnements de développement flexibles favorisant le travail collaboratif pour tirer parti de la diversité des profils et compétences des équipes de projet. Enfin, pour tirer pleinement parti de ces expérimentations, les statisticiens ont besoin d’outils pour déployer des applications sous forme de preuves de concept et orchestrer leurs opérations statistiques en toute autonomie.\nDans ce contexte, l’Insee a développé Onyxia : un projet open source permettant aux organisations de déployer des plateformes de data science favorisant l’innovation en offrant aux statisticiens une plus grande autonomie2. Cet article vise à décrire le processus de réflexion ayant conduit à ce projet et à illustrer comment il autonomise les statisticiens à l’Insee, devenant ainsi un pilier de notre stratégie d’innovation. La section 2 offre une analyse approfondie des derniers développements de l’écosystème de la donnée, mettant en lumière les choix technologiques qui ont façonné le développement d’un environnement moderne de data science, adapté aux besoins spécifiques des statisticiens. En particulier, nous montrons comment les technologies cloud — en particulier la conteneurisation et le stockage objet — sont essentielles pour créer des environnements évolutifs et flexibles qui favorisent l’autonomie tout en promouvant la reproductibilité des projets statistiques. Toutefois, malgré leurs atouts pour les applications modernes de data science, la complexité de configuration et d’utilisation des technologies cloud pose souvent des obstacles à leur adoption. Dans la section 3, nous détaillons le projet Onyxia vise précisément à rendre les technologies cloud accessibles aux statisticiens grâce à une interface conviviale et un catalogue étendu d’environnements de data science prêts à l’emploi. Enfin, à travers l’étude de cas de la classification des activités des entreprises françaises (APE), la section 4 illustre comment l’utilisation de ces technologies a considérablement facilité la mise en production de modèles d’apprentissage automatique à l’Insee en permettant d’appliquer les meilleures pratiques issues du MLOps.\n\n\n\n2 https://github.com/InseeFrLab/onyxia\n\n\nReferences\n\nAshofteh, Afshin, and Jorge M Bravo. 2021. “Data Science Training for Official Statistics: A New Scientific Paradigm of Information and Knowledge Development in National Statistical Systems.” Statistical Journal of the IAOS 37 (3): 771–89.\n\n\nDavenport, Thomas H, and DJ Patil. 2012. “Data Scientist.” Harvard Business Review 90 (5): 70–76.\n\n\nDescy, Pascaline, Vladimir Kvetan, Albrecht Wirthmann, and Fernando Reis. 2019. “Towards a Shared Infrastructure for Online Job Advertisement Data.” Statistical Journal of the IAOS 35 (4): 669–75.\n\n\nDGINS. 2018. “Bucharest Memorandum on Official Statistics in a Datafied Society.” https://ec.europa.eu/eurostat/documents/13019146/13237859/\\\\The+Bucharest+Memorandum+on+Trusted+Smart+Statistics+FINAL.pdf/7a8f6a8f-9805-e77c-a409-eb55a2b36bce?t=1634144384767.\n\n\nEUROSTAT. 2021. “ESSnet Big Data 2 - Final Technical Report.” https://wayback.archive-it.org/12090/20221110013641/https://ec.europa.eu/eurostat/cros/system/files/\\\\wpa_deliverable_a5_final_technical_report_2021_06_29.pdf.\n\n\nGjaltema, Taeke. 2022. “High-Level Group for the Modernisation of Official Statistics (HLG-MOS) of the United Nations Economic Commission for Europe.” Statistical Journal of the IAOS 38 (3): 917–22.\n\n\nINSEE. 2016. “Horizon 2025.” https://www.insee.fr/fr/statistiques/fichier/4130132/INSEE-2025.pdf.\n\n\nKowarik, Alexander, and Magdalena Six. 2022. “Quality Guidelines for the Acquisition and Usage of Big Data with Additional Insights on Web Data.” In 4th International Conference on Advanced Research Methods and Analytics (CARMA 2022), 269–69. Editorial Universitat Politècnica de València.\n\n\nLeclair, Marie, Isabelle Léonard, Guillaume Rateau, Patrick Sillard, Gaëtan Varlet, and Pierre Vernédal. 2019. “Scanner Data: Advances in Methodology and New Challenges for Computing Consumer Price Indices.” Economie Et Statistique 509 (1): 13–29.\n\n\nLiu, Ling. 2013. “Computing Infrastructure for Big Data Processing.” Frontiers of Computer Science 7: 165–70.\n\n\nRicciato, Fabio, Freddy De Meersman, Albrecht Wirthmann, Gerdy Seynaeve, and Michail Skaliotis. 2018. “Processing of Mobile Network Operator Data for Official Statistics: The Case for Public-Private Partnerships.” In 104th DGINS Conference.\n\n\nRicciato, Fabio, Albrecht Wirthmann, Konstantinos Giannakouris, Michail Skaliotis, et al. 2019. “Trusted Smart Statistics: Motivations and Principles.” Statistical Journal of the IAOS 35 (4): 589–603.\n\n\nSaiyeda, Anam, and Mansoor Ahmad Mir. 2017. “Cloud Computing for Deep Learning Analytics: A Survey of Current Trends and Challenges.” International Journal of Advanced Research in Computer Science 8 (2).\n\n\nSakarovitch, Benjamin, Marie-Pierre de Bellefon, Pauline Givord, and Maarten Vanhoof. 2018. “Estimating the Residential Population from Mobile Phone Data, an Initial Exploration.” Economie Et Statistique 505 (1): 109–32.\n\n\nSalgado, David, Luis Sanguiao-Sande, Sandra Barragán, Bogdan Oancea, and Milena Suarez-Castillo. 2020. “A Proposed Production Framework with Mobile Network Data.” In ESSnet Big Data II - Workpackage i - Mobile Network Data.",
    "crumbs": [
      "1 - Introduction"
    ]
  },
  {
    "objectID": "src/implementation/index.html",
    "href": "src/implementation/index.html",
    "title": "SSP Cloud Datalab",
    "section": "",
    "text": "TOTO",
    "crumbs": [
      "3 - Implémentation"
    ]
  },
  {
    "objectID": "src/discussion/index.html",
    "href": "src/discussion/index.html",
    "title": "SSP Cloud Datalab",
    "section": "",
    "text": "TOTO",
    "crumbs": [
      "5 - Discussion"
    ]
  }
]