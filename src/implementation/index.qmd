---
number-offset: 2
---

::: {.content-visible when-profile="en"}

# Onyxia: an open source project to build cloud-native data science platforms {#sec-implementation}

This section explores how Onyxia, an open-source project initiated at Insee, democratizes access to cloud technologies for statisticians by providing modern data science environments that foster autonomy. We discuss how this initiative fits in with the general aim of creating "knowledge commons" by promoting and building software that can be easily reused in the field of official statistics and beyond.

## Making cloud-technologies accessible to statisticians

Our technology watch and literature review highlighted cloud-native technologies, in particular containerization and object storage, as instrumental in building a data science platform that is both scalable and flexible. Building on these insights, we established our initial on-premise Kubernetes cluster in 2020, integrating it with MinIO, an open-source object storage system designed to work seamlessly with Kubernetes. Yet, our first experiments highlighted a significant barrier to the widespread adoption of cloud-native technologies: the complexity of their integration. This is an important consideration when building data architectures that prioritize modularity — an essential feature for the flexibility we aim to achieve[^flexibility]. However, modularity of the architecture components also entails that any data application launched on the cluster must be configured so as to communicate with all the components. For instance, in a big data setup, configuring Spark to operate on Kubernetes while interacting with datasets stored in MinIO requires an intricate set of configurations (specifying endpoints, access tokens, etc.), a skill set that typically lies beyond the expertise of statisticians.

[^flexibility]: A telling example of the importance of building a modular architecture is the ability to switch between storage sources (on-premise, public cloud provider, etc.). The storage solution we chose, MinIO, is compatible with Amazon's S3 API, which has become a de facto standard in the cloud ecosystem due to the success of Amazon's AWS S3 storage solution. As a result, organizations that choose to use Onyxia are not tied to a specific storage solution: they can choose any solution that complies with the standards defined by the S3 API.


For instance, due to MinIO's compatibility with the Amazon S3 API, the storage source could easily be switched to one managed by another public cloud provider, without requiring substantial modifications.

This insight is really the base of the Onyxia project: choosing technologies that foster autonomy will not actually foster autonomy if their complexity acts as a barrier from widespread adoption in the organization. In recent years, statisticians at Insee already needed to adapt to a changing environment in terms of their everyday tools: transitioning from proprietary software (SAS®) to open-source ones (R, Python), acculturating to technologies that improve reproducibility (version control with Git), consuming and developing APIs, etc. These changes, making their job more and more akin to the one of software developers, already imply significant training and changes in daily work practices. Against this background, adoption of cloud-technologies was utterly dependent on making them readily accessible.

![Onyxia is the technical binder between cloud-native modular components](../../figures/onyxia-components.png){#fig-onyxia-components}


To bridge this gap, we developed Onyxia, an application that essentially acts as interface between the modular components that compose the architecture (see @fig-onyxia-components). The main entry point of the user is a user-friendly web application[^onyxia-ui]  that enables users to launch services from a data science catalog (see @sec-catalog) as running containers on the underlying Kubernetes cluster. The interface between the UI and Kubernetes is done by a lightweight custom API[^onyxia-api], that essentially transforms the application request of the user into a set of manifests to deploy Kubernetes resources. For a given application, these resources are packaged under the form of Helm charts, a popular way of packaging potentially complex applications on Kubernetes [@gokhale2021creating]. Although users can configure a service to tailor it to their needs, they will most of the time just launch an out-of-the-box service with default settings and start developing straight away. This point really illustrates the added value of Onyxia in facilitating the adoption of cloud technologies. By injecting authentication information and configuration into the containers at the initialization, we ensure that users can launch and manage data science services in which they can interact seamlessly with the data from their bucket on MinIO, their sensitive information (tokens, passwords) in a secret management tool such as Vault, etc. This automatic injection, coupled with the pre-configuration of data science environments in Onyxia's catalogs of images[^images-datascience] and associated helm-charts[^helm-charts-interactive-services], make it possible for users to execute potentially complex workloads — such as running distributed computations with Spark on Kubernetes using data stored in S3, or training deep-learning models using a GPU — without getting bogged down by the technicalities of configuration.

[^onyxia-ui]: [https://github.com/InseeFrLab/onyxia-ui]()
[^onyxia-api]: [https://github.com/InseeFrLab/onyxia-api]()
[^images-datascience]: [https://github.com/InseeFrLab/images-datascience]()
[^helm-charts-interactive-services]: [https://github.com/InseeFrLab/helm-charts-interactive-services]()

## Architectural choices aimed at fostering autonomy {#sec-principles-autonomy}

The Onyxia project is based on a few structuring principles, with a central theme: fostering autonomy, both at the organizational and individual levels. First, at the level of the organization by preventing vendor lock-in. In order to get a competitive edge, many commercial cloud providers develop applications and protocols that customers need to use to access cloud resources, but that are not interoperable, greatly complexifying potential migrations to another cloud platform [@opara2016critical]. Recognizing these challenges, there is a trend towards endorsing cloud-neutral strategies [@opara2017holistic] in order to reduce reliance on a single vendor’s specific solutions. In contrast, the use of Onyxia is inherently not restrictive: when an organization chooses to use it, it chooses the underlying technologies — containerization and object storage — but not the solution. The platform can be deployed on any Kubernetes cluster, either on-premise or in public clouds. Similarly, Onyxia was designed to be used with MinIO because it is an open-source object-storage solution, but is also compatible with objects storage solutions from various cloud providers (AWS, GCP).

Onyxia also fosters autonomy at the level of users. Proprietary softwares that have been used intensively in official statistics — such as SAS or STATA — also produce a vendor lock-in phenomenon. The costs of licensing are high and can evolve quickly, and users are tied in certain ways of performing computations, preventing progressive upskilling. On the contrary, Onyxia aspires to be removable; we want to enhance users' familiarity and comfort with the underlying cloud technologies rather than act as a permanent fixture in their workflow. An illustrative example of this philosophy is the platform's approach to user actions: for tasks performed through the UI, such as launching a service or managing data, we provide users with the equivalent terminal commands, promoting a deeper understanding of what actually happens on the infrastructure when triggering something. Furthermore, all the services offered through Onyxia's catalog are open-source.

![Launching a service through Onyxia's UI.](../../figures/service-configuration.png){#fig-service-configuration}

Note: Services from Onyxia's catalog can either be used vanilla or configured by the users to tailor them to their specific needs. In order to limit the dependence of users on Onyxia, each action performed by the user on the UI is accompanied by the actual command that is executed on the Kubernetes cluster.


Naturally, the way Onyxia makes statisticians more autonomous in their work depends on their needs and familiarity with IT skills. Statisticians that just want to have access to extensive computational resources to experiment with new data sources or statistical methods will have access in a few clicks to easy-to-use, pre-configured data science environments, so that they can directly start to experiment. However, many users want to go deeper and build actual prototypes of production applications for their projects: configuring initialization scripts to tailor the environments to their needs, deploying an interactive app that delivers data visualization to users of their choice, deploying other services than those available in our catalogs, etc. For these advanced users to continue to push the boundaries of innovation, Onyxia gives them access to the underlying Kubernetes cluster. This means that users can freely open a terminal on an interactive service and interacts with the cluster - within the boundaries of their namespace - in order to apply custom resources and deploy custom applications or services.

Besides autonomy and scalability, the architectural choices of Onyxia also foster reproducibility of statistical computations. In the paradigm of containers, the user must learn to deal with resources which are by nature ephemeral, since they only exist at the time of their actual mobilization. This fosters the adoption of development best practices, notably the separation of the code — put on an internal or open-source forge such as GitLab or GitHub — the data — stored on a specific storage solution, such as MinIO — and the computing environment. While this requires an entry cost for users, it also helps them to conceive their projects as pipelines, i.e. a series of sequential steps with well-defined inputs and outputs (akin to directed acyclic graph (DAG)). The projects developed in that manner are usually more reproducible and portable — they can work seamlessly on different computing environments — and thus also more readily shareable with peers.

## An extensive catalogue of services to cover the entire lifecycle of data science projects {#sec-catalog}

In developing the Onyxia platform, our intention was to provide statisticians with a comprehensive environment designed to support end-to-end development of data science projects. As depicted in @fig-onyxia-catalog, the platform offers a vast array of services that span the complete lifecycle of a data science project.

![Onyxia's catalog aims at covering the entire lifecycle of data science projects](../../figures/onyxia-catalog.png){#fig-onyxia-catalog}

The primary usage of the platform is the deployment of interactive development environments (IDE), such as RStudio, Jupyter, or VSCode. These IDEs come equipped with the latest kernels of major open-source programming languages commonly employed by public statisticians (R, Python, Julia), as well as an extensive collection of packages commonly used in data science for each language. In order to ensure that services remain up-to-date and consistent between them, we maintain our own stack of underlying Docker images and rebuild it weekly. The stack of images is fully open-source[^images-datascience] and can thus be reused outside Onyxia.


As discussed in previous sections, the persistence layer of these interactive environments is mainly carried out by MinIO, Onyxia's default object storage solution. As it is based on a standardized REST API, files can be easily queried directly from R or Python using high-level packages. This in itself is an important step of ensuring reproducibility: the input files of a project are not mounted manually and then specified via paths adherent to a specific infrastructure and filesystem. Rather, files are specified as HTTP queries, making the overall structure of projects much more extendable. In our experience, the object-storage paradigm covers very well the needs of most statistical projects we accompany. However, additional database services such as PostgreSQL and MongoDB are available for applications with specific needs, such as those requiring online transaction processing (OLTP) capabilities or document-oriented storage.

As Onyxia was developed to allow experimentation with big data sources and machine learning methods, we also provide services optimized for scalability. For instance, frameworks like Spark and Trino that enable to perform distributed computations within Kubernetes. These services come pre-configured to integrate seamlessly with S3 storage, thus facilitating building integrated and efficient data pipelines.

Beyond mere experimentation, our goal is to empower statisticians to transition from trial phases to production-grade projects. In lines with principles from the DevOps approach, this involves facilitating the deployment of prototypes and their continuous improvement over time. To this end, we provide a set of open-source tools aimed at automatizing and industrializing the process of deploying data-intensive applications (ArgoCD, Argo-Workflows, MLflow). For projects leveraging machine-learning models, statisticians can serve their models through APIs, deploy them using the aforementioned tools, and manage their lifecycle using an API manager (e.g. Gravitee). [Section 4](../mlops/index.qmd#sec-mlops) will illustrate how these tools, particularly MLflow, have been central in putting machine learning models in production at Insee, in accordance with MLOps principles.

In @sec-principles-autonomy, we stressed that one of Onyxia's fundamental design principle was to avoid vendor lock-in. In line with this idea, organizations that implement Onyxia are free to customize catalogs to suit their specific requirements, or even opt to construct their own catalogs independent of Onyxia's default offerings. This flexibility ensures that organizations are not confined to a single solution or provider, and can adapt the platform to their evolving needs.

## Building commons: an open-source project and an open-innovation platform

As a fully open-source initiative, the Onyxia project aims at building "knowledge commons" by promoting and building software that can be easily reused in official statistics and beyond [@schweik2006free]. This concerns, first of all, the components on which Onyxia are based: both its constitutive technological bricks (Kubernetes, MinIO, Vault) as well as all the services from the catalog are open-source. But more crucially, all the code of the project is available openly on GitHub[^onyxia-github]. Alongside an in-depth documentation[^onyxia-docs], this greatly facilitates the potential for other organizations to create instances of data science platforms built upon the Onyxia software and tailor it to their respective needs (see @fig-onyxia-instances). This enabled the project to attract a growing community of contributors from official statistics (Statistics Norway), NGOs (Mercator Ocean), research centres and even industry, thus transitioning progressively towards a more decentralized governance of the project. In the next years, the involvement of NSIs from the European Statistical System is expected to increase as Onyxia was chosen as the reference data science platform in the context of the AIML4OS project, a "One-Stop-Shop" for Artificial Intelligence/Machine Learning for Official Statistics in the European Statistical System[^aiml4os].

[^onyxia-github]: [https://github.com/InseeFrLab/onyxia]()
[^onyxia-docs]: [https://docs.onyxia.sh/]()
[^aiml4os]: More information on this project available at [https://cros.ec.europa.eu/dashboard/aiml4os]()

![One project, multiple instances: the UI is adaptable to the graphic identity of the organization](../../figures/onyxia-instances.png){#fig-onyxia-instances}

Another major way in which we try to build commons is by developing and maintaining a showcase instance of the Onyxia project, the SSP Cloud [@comte2022sspcloud]. This platform, equipped with extensive and scalable computational resources[^cluster], is designed to be a sandbox for experimenting with cloud technologies and new data science methods. The full catalog of services of Onyxia is available on the platform, enabling motivated users to go beyond mere experimentation by producing "proof of concepts", with full autonomy regarding the configuration and orchestration of their services.

[^cluster]: On the physical side, the SSP Cloud consists in a Kubernetes cluster of about 20 servers, for a total capacity of 10 TB of RAM, 1100 CPUs, 34 GPUs and 150 TB of storage.

Beyond its technical capabilities, the SSP Cloud is an endeavour at embodying the principles of open-innovation [@chesbrough2003open]. Deployed on internet[^datalab], it is open not only to Insee employees, but also more broadly to French governmental agencies, French Universities and other European NSIs, and is dedicated to experimenting with data science methods using open data. Thus, the projects carried out on this platform showcase the growing abundance of datasets published openly by organizations. The fundamentally collaborative nature of the SSP Cloud has proven especially beneficial for organizing innovative events such as hackathons — both at the national and international levels — and in the academic sphere. It has become an integral resource for several universities and Grandes Ecoles in France, fostering the use of cloud-native and reproducible environments, and preventing vendor lock-in effect due to the over-reliance of educational organizations on proprietary cloud solutions. As a result, the platform is now widely used in the French National Statistical System and beyond, with about 800 unique users per month in 2024. These users form a dynamic community thanks to a centralized discussion canal; they help improve the user experience by reporting bugs, suggesting new features, and thus contribute directly to the project.

[^datalab]: [https://datalab.sspcloud.fr/]()


:::


<!-- ############################################################################################################## -->
<!-- ############################################################################################################## -->
<!-- ############################################################################################################## -->



::: {.content-visible when-profile="fr"}

# Onyxia : un projet open source pour construire des plateformes de data science sur des technologies cloud{#sec-implementation-fr}

Cette section examine comment Onyxia, un projet open source initié par l’Insee, démocratise l’accès aux technologies *cloud* pour les statisticiens en fournissant des environnements modernes de *data science* favorisant l’autonomie. Nous analysons comment cette initiative s’inscrit dans l’objectif général de création des "connaissances communes" en promouvant et en développant des logiciels facilement réutilisables dans le domaine des statistiques publiques et ailleurs.

## Rendre les technologies cloud accessibles aux statisticiens

Notre veille technologique et notre revue de la littérature ont mis en évidence les technologies *cloud*, en particulier la conteneurisation et le stockage d’objets, comme des éléments clés pour construire une plateforme de *data science* à la fois scalable et flexible. En nous appuyant sur ces enseignements, nous avons mis en place notre premier cluster Kubernetes dans les locaux de l'Insee en 2020, en l’intégrant avec MinIO, un système de stockage d’objets *open source* conçu pour fonctionner de manière fluide avec Kubernetes. Cependant, nos premières expérimentations ont révélé un obstacle majeur à l’adoption généralisée des technologies *cloud* : la complexité de leur intégration. C’est une considération importante lorsqu’il s’agit de construire des architectures de données qui privilégient la modularité — une caractéristique essentielle pour atteindre la flexibilité que nous visons[^flexibilité]. Toutefois, la modularité des composants architecturaux implique également que toute application de données lancée sur le cluster doit être configurée pour communiquer avec tous les autres composants. Par exemple, dans un environnement *big data*, la configuration de Spark pour fonctionner sur Kubernetes tout en interagissant avec des ensembles de données stockés dans MinIO nécessite de nombreuses et complexes configurations (définition des points d'entrée, des jetons d’accès, etc.), une compétence qui dépasse généralement l’expertise des statisticiens.


[^flexibilité]: Un exemple révélateur de l'importance de construire une architecture modulaire est la capacité de basculer entre différentes sources de stockage (on-premise, fournisseur de *cloud* public, etc.). La solution de stockage que nous avons choisie, MinIO, est compatible avec l’API S3 d’Amazon, qui est devenue un standard *de facto* dans l’écosystème *cloud* grâce au succès de la solution de stockage S3 d’Amazon AWS. Ainsi, les organisations qui choisissent d'utiliser Onyxia ne sont pas liées à une solution de stockage spécifique : elles peuvent opter pour n'importe quelle solution conforme aux standards définis par l'API S3.

Par exemple, grâce à la compatibilité de MinIO avec l’API S3 d’Amazon, la source de stockage pourrait facilement être remplacée par une solution gérée par un autre fournisseur de *cloud* public, sans nécessiter de modifications substantielles.

Cette idée est véritablement le fondement du projet Onyxia : choisir des technologies qui favorisent l’autonomie ne remplira pas cet objectif si leur complexité constitue une barrière à une adoption généralisée au sein de l’organisation. Ces dernières années, les statisticiens de l’Insee ont déjà dû s’adapter à un environnement en évolution en ce qui concerne leurs outils quotidiens : passer de logiciels propriétaires (SAS®) à des outils open source (R, Python), s’approprier des technologies qui améliorent la reproductibilité (contrôle de version avec Git), consommer et développer des API, etc. Ces changements, rendant leur travail de plus en plus semblable à celui de développeurs logiciels, impliquent déjà des efforts considérables en termes de formation et des modifications des pratiques de travail quotidiennes. Dans ce contexte, l’adoption des technologies *cloud* dépend totalement de leur accessibilité immédiate.

![Onyxia est le lien technique entre les composants modulaires du cloud.](../../figures/onyxia-components.png){#fig-onyxia-components}


Pour combler cet écart, nous avons développé Onyxia, une application qui agit essentiellement comme une interface entre les composants modulaires qui composent l’architecture (voir @fig-onyxia-components). Le point d’entrée principal pour l’utilisateur est une application web ergonomique[^onyxia-ui] qui lui permet de lancer des services à partir d’un catalogue de *data science* (voir @sec-catalog) sous forme de conteneurs exécutés sur le cluster Kubernetes sous-jacent. Le lien entre l’interface utilisateur (UI) et Kubernetes est assurée par une API [^onyxia-api], qui transforme essentiellement la demande d’application de l’utilisateur en un ensemble de manifestes nécessaires pour déployer des ressources Kubernetes. Pour une application donnée, ces ressources sont regroupées sous la forme de *charts* Helm, une méthode populaire pour empaqueter des applications potentiellement complexes sur Kubernetes [@gokhale2021creating]. Bien que les utilisateurs puissent configurer un service pour l’adapter à leurs besoins, la plupart du temps, ils se contentent de lancer un service prêt à l’emploi avec des paramètres par défaut et commencent à développer immédiatement. Ce point illustre parfaitement la valeur ajoutée d’Onyxia pour faciliter l’adoption des technologies cloud. En injectant automatiquement les informations d’authentification et de configuration dans les conteneurs lors de leur initialisation, nous veillons à ce que les utilisateurs puissent lancer et gérer des services de *data science* dans lesquels ils interagissent sans difficulté avec les données de leur *bucket* sur MinIO, leurs informations sensibles (jetons, mots de passe) dans un outil de gestion des secrets tel que Vault, etc. Cette injection automatique, associée à la pré-configuration des environnements de *data science* dans les catalogues d’images[^images-datascience] et de *charts* Helm[^helm-charts-interactive-services] d’Onyxia, permet aux utilisateurs d’exécuter des scripts potentiellement complexes — comme des calculs distribués avec Spark sur Kubernetes à l’aide de données stockées sur S3, ou l’entraînement de modèles d’apprentissage profond utilisant un GPU — sans se heurter aux difficultés techniques liées à la configuration.

[^onyxia-ui]: [https://github.com/InseeFrLab/onyxia-ui]()
[^onyxia-api]: [https://github.com/InseeFrLab/onyxia-api]()
[^images-datascience]: [https://github.com/InseeFrLab/images-datascience]()
[^helm-charts-interactive-services]: [https://github.com/InseeFrLab/helm-charts-interactive-services]()

## Des choix architecturaux visant à favoriser l'autonomie des statisticiens {#sec-principles-autonomy-fr}

Le projet Onyxia repose sur quelques principes structurants, avec un thème central : favoriser l'autonomie, à la fois au niveau organisationnel et individuel. Tout d'abord, au niveau de l'organisation, en évitant l'enfermement propriétaire. Pour obtenir un avantage concurrentiel, de nombreux fournisseurs de *cloud* commerciaux développent des applications et protocoles spécifiques que les clients doivent utiliser pour accéder aux ressources *cloud*, mais qui ne sont pas interopérables, compliquant considérablement les migrations potentielles vers une autre plateforme *cloud* [@opara2016critical]. Sachant cela, une tendance émerge vers l'adoption de stratégies neutres vis-à-vis des *clouds* [@opara2017holistic] afin de réduire la dépendance à des solutions spécifiques d'un seul fournisseur. En revanche, l'utilisation d'Onyxia n'est intrinsèquement pas restrictive : lorsqu'une organisation choisit de l'utiliser, elle choisit les technologies sous-jacentes — la conteneurisation et le stockage d'objets — mais pas la solution en elle-même. La plateforme peut être déployée sur n'importe quel cluster Kubernetes, qu'il soit *on-premise* ou sur des *clouds* commerciaux. De même, Onyxia a été conçue pour être utilisée avec MinIO, car il s'agit d'une solution de stockage d'objets *open source*, mais il est également possible de l'utiliser avec les solutions de stockage d'objets proposées par divers fournisseurs de *cloud* (AWS, GCP, etc.).

Onyxia favorise également l'autonomie au niveau des utilisateurs. Les logiciels propriétaires qui ont été intensivement utilisés dans les statistiques officielles — comme SAS ou STATA — induisent également un phénomène d'enfermement propriétaire. Les coûts des licences sont élevés et peuvent évoluer rapidement, et les utilisateurs se retrouvent dépendants de certaines méthodes de calcul, empêchant une montée en compétences progressive. Au contraire, Onyxia aspire à être amovible ; nous souhaitons améliorer la familiarité et le confort des utilisateurs avec les technologies *cloud* sous-jacentes plutôt que de devenir un élément permanent travail quotidien. Un exemple illustratif de cette philosophie est l'approche de la plateforme concernant les actions des utilisateurs : pour les tâches effectuées via l'interface utilisateur, comme le lancement d'un service ou la gestion des données, nous fournissons aux utilisateurs les commandes terminal équivalentes, promouvant ainsi une compréhension plus approfondie de ce qui se passe réellement lors du déclenchement d'une action. De plus, tous les services proposés via le catalogue d'Onyxia sont *open source*.

![Lancer un service via l'interface web d'Onyxia.](../../figures/service-configuration.png){#fig-service-configuration}

Note: Les services du catalogue d'Onyxia peuvent être utilisés tels quels ou configurés par les utilisateurs pour répondre à leurs besoins spécifiques. Afin de limiter la dépendance des utilisateurs vis-à-vis d'Onyxia, chaque action effectuée par l'utilisateur via l'interface utilisateur est accompagnée de la commande exacte exécutée sur le cluster Kubernetes.

Naturellement, la manière dont Onyxia rend les statisticiens plus autonomes dans leur travail dépend de leurs besoins et de leur familiarité avec les compétences informatiques. Les statisticiens qui souhaitent simplement accéder à des ressources de calcul importantes pour expérimenter avec de nouvelles sources de données ou méthodes statistiques pourront, en quelques clics, accéder à des environnements de *data science* préconfigurés et faciles à utiliser, leur permettant de commencer à expérimenter immédiatement. Cependant, de nombreux utilisateurs souhaitent aller plus loin et développer de véritables prototypes d'applications de production pour leurs projets : configurer des scripts d'initialisation pour adapter les environnements à leurs besoins, déployer une application interactive offrant des visualisations de données aux utilisateurs de leur choix, ou encore déployer d'autres services que ceux disponibles dans nos catalogues. Pour permettre à ces utilisateurs avancés de continuer à repousser les limites de l'innovation, Onyxia leur donne accès au cluster Kubernetes sous-jacent. Cela signifie que les utilisateurs peuvent ouvrir librement un terminal sur un service interactif et interagir avec le cluster — dans les limites de leur *namespace* — afin d'appliquer des ressources personnalisées et de déployer des applications ou services personnalisés.

Au-delà de l'autonomie et de la scalabilité, les choix architecturaux d'Onyxia favorisent également la reproductibilité des calculs statistiques. Dans le paradigme des conteneurs, l'utilisateur doit apprendre à gérer des ressources qui sont par nature éphémères, puisqu'elles n'existent qu'au moment de leur mobilisation effective. Cela encourage l'adoption de bonnes pratiques de développement, notamment la séparation du code — hébergé sur une forge interne ou *open source* telle que GitLab ou GitHub —, des données — stockées sur une solution de stockage spécifique, comme MinIO —, et de l'environnement de calcul. Bien que cela impose un coût d'entré non négligeable aux utilisateurs, cela les aide également à concevoir leurs projets sous forme de *pipelines*, c'est-à-dire une série d'étapes séquentielles avec des données en entrées et productions finales bien définies (semblables à un graphe orienté acyclique, ou DAG). Les projets développés de cette manière sont généralement plus reproductibles et transposables — ils peuvent fonctionner sans problème sur différents environnements de calcul — et sont ainsi plus facilement partageables avec leurs pairs.


## Un catalogue exhaustif de services pour couvrir l'ensemble du cycle de vie des projets de data science {#sec-catalog}

Lors du développement de la plateforme Onyxia, notre intention était de fournir aux statisticiens un environnement complet conçu pour accompagner le développement de bout en bout des projets de *data science*. Comme illustré dans @fig-onyxia-catalog, la plateforme propose une vaste gamme de services couvrant l'ensemble du cycle de vie d'un projet de *data science*.

![Le catalogue d'Onyxia vise à couvrir l'ensemble du cycle de vie des projets de data science](../../figures/onyxia-catalog.png){#fig-onyxia-catalog}

L'utilisation principale de la plateforme est le déploiement d'environnements de développement interactifs (IDE), tels que RStudio, Jupyter ou VSCode. Ces IDE sont équipés des dernières versions des principaux langages de programmation *open source* couramment utilisés par les statisticiens publics (R, Python, Julia), ainsi que d'une vaste collection de librairies fréquemment employées en *data science* pour chaque langage. Afin de garantir que les services restent à jour et cohérents entre eux, nous maintenons nos propres images Docker sous-jacentes et les mettons à jour chaque semaine. Ces images sont entièrement *open source*[^images-datascience] et peuvent donc être réutilisée en dehors d'Onyxia.

Comme discuté dans les sections précédentes, la couche de persistance de ces environnements interactifs est principalement assurée par MinIO, la solution de stockage d'objets par défaut d'Onyxia. Étant basé sur une API REST standardisée, les fichiers peuvent être facilement interrogés depuis R ou Python à l'aide de librairies de haut niveau. Cela représente en soi une étape importante pour garantir la reproductibilité : les données ne sont pas sauvegardés localement, puis spécifiés via des chemins propres à une infrastructure ou un système de fichiers particulier. Au contraire, les fichiers sont spécifiés sous forme de requêtes HTTP, rendant la structure globale des projets bien plus extensible. D’après notre expérience, le paradigme du stockage d'objets répond très bien aux besoins de la plupart des projets statistiques que nous accompagnons. Cependant, des services de bases de données supplémentaires, tels que PostgreSQL et MongoDB, sont disponibles pour les applications ayant des besoins spécifiques, notamment celles nécessitant des capacités de traitement transactionnel en ligne (OLTP) ou un stockage orienté documents.

Comme Onyxia a été développée pour permettre l'expérimentation avec des sources de données volumineuses et des méthodes d'apprentissage automatique, nous proposons également des services optimisés pour passé à l'échelle facilement. Par exemple, des frameworks comme Spark et Trino, qui permettent d'effectuer des calculs distribués au sein d'un cluster Kubernetes. Ces services sont préconfigurés pour s'intégrer parfaitement avec le stockage S3, facilitant ainsi la création de *pipelines* de données intégrés et efficaces.

Au-delà de la simple expérimentation, notre objectif est de permettre aux statisticiens de passer des phases de test à des projets de qualité proche de celle requise en production afin de réduire le coût lors de la transmission d'un projet d'une équipe de production vers une équipe informatique. Conformément aux principes de l'approche DevOps, cela implique de faciliter le déploiement de prototypes et leur amélioration continue au fil du temps. À cette fin, nous proposons un ensemble de services *open source* visant à automatiser et industrialiser le processus de déploiement d'applications (ArgoCD, Argo-Workflows, MLflow). Pour les projets exploitant des modèles d'apprentissage automatique, les statisticiens peuvent exposer leurs modèles via des API, les déployer en utilisant les outils susmentionnés et gérer leur cycle de vie grâce à un gestionnaire d'API (par exemple, Gravitee). La [Section 4](../mlops/index.qmd#sec-mlops) illustrera comment ces outils, en particulier MLflow, ont joué un rôle central dans la mise en production de modèles d'apprentissage automatique à l’Insee, en lien avec les principes de MLOps.

Dans la @sec-principles-autonomy-fr, nous avons souligné qu'un des principes fondamentaux de conception d'Onyxia était d'éviter l'enfermement propriétaire. Dans cette optique, les organisations qui instancient Onyxia sont libres de personnaliser les catalogues pour répondre à leurs besoins spécifiques, ou même de créer leurs propres catalogues indépendamment des offres par défaut d'Onyxia. Cette flexibilité garantit aux organisations de ne pas être limité à une solution ou à un fournisseur unique, et qu'elles peuvent adapter la plateforme à l'évolution de leurs besoins.

## Construire des biens communs : un projet open source et une plateforme d'innovation ouverte

En tant qu'initiative entièrement *open source*, le projet Onyxia vise à construire des « connaissances communes » en promouvant et en développant des logiciels facilement réutilisables dans les statistiques publiques et ailleurs [@schweik2006free]. Cela concerne, tout d'abord, les composants sur lesquels repose Onyxia : à la fois ses briques technologiques (Kubernetes, MinIO, Vault) et l'ensemble des services du catalogue, qui sont *open source*. Plus important encore, tout le code du projet est disponible publiquement sur GitHub[^onyxia-github]. Associée à une documentation détaillée[^onyxia-docs], cette transparence facilite grandement la possibilité pour d'autres organisations de créer des instances de plateformes de *data science* basées sur le logiciel Onyxia et de les adapter à leurs besoins spécifiques (voir @fig-onyxia-instances). Cela a permis au projet d'attirer une communauté croissante de contributeurs issus des statistiques publiques (Statistique Norvège), des ONG (Mercator Ocean[^mercator]), des centres de recherche et même de l'industrie, favorisant ainsi une transition progressive vers une gouvernance plus décentralisée du projet. 

Dans les prochaines années, l'implication des INS (Instituts Nationaux de Statistique) du système statistique européen devrait augmenter, puisque le SSPCloud a été choisie comme plateforme *data science* de référence dans le cadre du projet AIML4OS[^aiml4os].

[^mercator]: Lien vers l'instance Onyxia de Mercator Ocean : [https://datalab.dive.edito.eu/]()
[^onyxia-github]: [https://github.com/InseeFrLab/onyxia]()
[^onyxia-docs]: [https://docs.onyxia.sh/]()
[^aiml4os]: Plus d'informations à propos de ce projet disponibles à [https://cros.ec.europa.eu/dashboard/aiml4os]()

![Un projet, de multiples instances : l'interface web est adaptable à l'identité graphique de chaque organisation](../../figures/onyxia-instances.png){#fig-onyxia-instances}

Une autre manière majeure de construire des communs est le développement et le maintien d'une instance de démonstration du projet Onyxia, le SSP Cloud [@comte2022sspcloud]. Cette plateforme, équipée de ressources de calcul extensives et évolutives[^cluster], est conçue comme un bac à sable pour expérimenter avec les technologies cloud et les nouvelles méthodes de science des données. Le catalogue complet des services d'Onyxia est disponible sur cette plateforme, permettant aux utilisateurs motivés d'aller au-delà de la simple expérimentation en produisant des « preuves de concept » avec une autonomie totale concernant la configuration et l'orchestration de leurs services.

[^cluster]: Sur le plan matériel, le SSP Cloud est constitué d'un cluster Kubernetes d'environ 20 serveurs, pour une capacité totale de 10 To de RAM, 1100 processeurs, 34 GPU et 150 To de stockage.

Au-delà de ses capacités techniques, le SSP Cloud incarne les principes de l'innovation ouverte [@chesbrough2003open]. Déployé sur internet[^datalab], il est accessible non seulement aux employés de l'Insee, mais également, plus largement, aux agences gouvernementales françaises, aux universités françaises et aux autres INS européens. Il est dédié à l'expérimentation des méthodes de *data science* en utilisant des données ouvertes. Ainsi, les projets menés sur cette plateforme mettent en lumière l'abondance croissante des jeux de données publiés en libre accès par les organisations publiques ou privés, faisant écho à la loi pour une République numérique de 2016. La nature fondamentalement collaborative du SSP Cloud s'est avérée particulièrement bénéfique pour l'organisation d'événements innovants, tels que des hackathons — tant au niveau national qu'international — et dans le domaine académique. Il est devenu une ressource intégrale pour plusieurs universités et Grandes Écoles en France, favorisant l'utilisation d'environnements *cloud* et reproductibles, tout en évitant l'effet d'enfermement propriétaire dû à une dépendance excessive des institutions éducatives envers des solutions *cloud* propriétaires. En conséquence, la plateforme est désormais largement utilisée dans le service statistique publique français et ailleurs, avec environ 1000 utilisateurs uniques par mois début 2025. Ces utilisateurs forment une communauté dynamique grâce à un canal de discussion centralisé[^tchap_sspcloud] ; ils contribuent à améliorer l'expérience utilisateur en signalant des bugs, en proposant de nouvelles fonctionnalités et en participant ainsi directement au projet.


[^datalab]: [https://datalab.sspcloud.fr/]()

[^tchap_sspcloud]: Lien vers les canaux de discussion [https://www.tchap.gouv.fr/#/room/#SSPCloudXDpAw6v:agent.finances.tchap.gouv.fr](Tchap) et [https://join.slack.com/t/3innovation/shared_invite/zt-19tht9hvr-bZGMdW8AV_wvd5kz3wRSMw](Slack)


::: 