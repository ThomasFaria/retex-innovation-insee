---
number-offset: 2
---

::: {.content-visible when-profile="en"}

# Onyxia: an open source project to build cloud-native data science platforms {#sec-implementation}

This section explores how Onyxia, an open-source project initiated at Insee, democratizes access to cloud technologies for statisticians by providing modern data science environments that foster autonomy. We discuss how this initiative fits in with the general aim of creating "knowledge commons" by promoting and building software that can be easily reused in the field of official statistics and beyond.

## Making cloud-technologies accessible to statisticians

Our technology watch and literature review highlighted cloud-native technologies, in particular containerization and object storage, as instrumental in building a data science platform that is both scalable and flexible. Building on these insights, we established our initial on-premise Kubernetes cluster in 2020, integrating it with MinIO, an open-source object storage system designed to work seamlessly with Kubernetes. Yet, our first experiments highlighted a significant barrier to the widespread adoption of cloud-native technologies: the complexity of their integration. This is an important consideration when building data architectures that prioritize modularity — an essential feature for the flexibility we aim to achieve[^flexibility]. However, modularity of the architecture components also entails that any data application launched on the cluster must be configured so as to communicate with all the components. For instance, in a big data setup, configuring Spark to operate on Kubernetes while interacting with datasets stored in MinIO requires an intricate set of configurations (specifying endpoints, access tokens, etc.), a skill set that typically lies beyond the expertise of statisticians.

[^flexibility]: A telling example of the importance of building a modular architecture is the ability to switch between storage sources (on-premise, public cloud provider, etc.). The storage solution we chose, MinIO, is compatible with Amazon's S3 API, which has become a de facto standard in the cloud ecosystem due to the success of Amazon's AWS S3 storage solution. As a result, organizations that choose to use Onyxia are not tied to a specific storage solution: they can choose any solution that complies with the standards defined by the S3 API.


For instance, due to MinIO's compatibility with the Amazon S3 API, the storage source could easily be switched to one managed by another public cloud provider, without requiring substantial modifications.

This insight is really the base of the Onyxia project: choosing technologies that foster autonomy will not actually foster autonomy if their complexity acts as a barrier from widespread adoption in the organization. In recent years, statisticians at Insee already needed to adapt to a changing environment in terms of their everyday tools: transitioning from proprietary software (SAS®) to open-source ones (R, Python), acculturating to technologies that improve reproducibility (version control with Git), consuming and developing APIs, etc. These changes, making their job more and more akin to the one of software developers, already imply significant training and changes in daily work practices. Against this background, adoption of cloud-technologies was utterly dependent on making them readily accessible.

![Onyxia is the technical binder between cloud-native modular components](../../figures/onyxia-components.png){#fig-onyxia-components}


To bridge this gap, we developed Onyxia, an application that essentially acts as interface between the modular components that compose the architecture (see @fig-onyxia-components). The main entry point of the user is a user-friendly web application[^onyxia-ui]  that enables users to launch services from a data science catalog (see @sec-catalog) as running containers on the underlying Kubernetes cluster. The interface between the UI and Kubernetes is done by a lightweight custom API[^onyxia-api], that essentially transforms the application request of the user into a set of manifests to deploy Kubernetes resources. For a given application, these resources are packaged under the form of Helm charts, a popular way of packaging potentially complex applications on Kubernetes [@gokhale2021creating]. Although users can configure a service to tailor it to their needs, they will most of the time just launch an out-of-the-box service with default settings and start developing straight away. This point really illustrates the added value of Onyxia in facilitating the adoption of cloud technologies. By injecting authentication information and configuration into the containers at the initialization, we ensure that users can launch and manage data science services in which they can interact seamlessly with the data from their bucket on MinIO, their sensitive information (tokens, passwords) in a secret management tool such as Vault, etc. This automatic injection, coupled with the pre-configuration of data science environments in Onyxia's catalogs of images[^images-datascience] and associated helm-charts[^helm-charts-interactive-services], make it possible for users to execute potentially complex workloads — such as running distributed computations with Spark on Kubernetes using data stored in S3, or training deep-learning models using a GPU — without getting bogged down by the technicalities of configuration.

[^onyxia-ui]: [https://github.com/InseeFrLab/onyxia-ui]()
[^onyxia-api]: [https://github.com/InseeFrLab/onyxia-api]()
[^images-datascience]: [https://github.com/InseeFrLab/images-datascience]()
[^helm-charts-interactive-services]: [https://github.com/InseeFrLab/helm-charts-interactive-services]()

## Architectural choices aimed at fostering autonomy {#sec-principles-autonomy}

The Onyxia project is based on a few structuring principles, with a central theme: fostering autonomy, both at the organizational and individual levels. First, at the level of the organization by preventing vendor lock-in. In order to get a competitive edge, many commercial cloud providers develop applications and protocols that customers need to use to access cloud resources, but that are not interoperable, greatly complexifying potential migrations to another cloud platform [@opara2016critical]. Recognizing these challenges, there is a trend towards endorsing cloud-neutral strategies [@opara2017holistic] in order to reduce reliance on a single vendor’s specific solutions. In contrast, the use of Onyxia is inherently not restrictive: when an organization chooses to use it, it chooses the underlying technologies — containerization and object storage — but not the solution. The platform can be deployed on any Kubernetes cluster, either on-premise or in public clouds. Similarly, Onyxia was designed to be used with MinIO because it is an open-source object-storage solution, but is also compatible with objects storage solutions from various cloud providers (AWS, GCP).

Onyxia also fosters autonomy at the level of users. Proprietary softwares that have been used intensively in official statistics — such as SAS or STATA — also produce a vendor lock-in phenomenon. The costs of licensing are high and can evolve quickly, and users are tied in certain ways of performing computations, preventing progressive upskilling. On the contrary, Onyxia aspires to be removable; we want to enhance users' familiarity and comfort with the underlying cloud technologies rather than act as a permanent fixture in their workflow. An illustrative example of this philosophy is the platform's approach to user actions: for tasks performed through the UI, such as launching a service or managing data, we provide users with the equivalent terminal commands, promoting a deeper understanding of what actually happens on the infrastructure when triggering something. Furthermore, all the services offered through Onyxia's catalog are open-source.

![Launching a service through Onyxia's UI.](../../figures/service-configuration.png){#fig-service-configuration}

Note: Services from Onyxia's catalog can either be used vanilla or configured by the users to tailor them to their specific needs. In order to limit the dependence of users on Onyxia, each action performed by the user on the UI is accompanied by the actual command that is executed on the Kubernetes cluster.


Naturally, the way Onyxia makes statisticians more autonomous in their work depends on their needs and familiarity with IT skills. Statisticians that just want to have access to extensive computational resources to experiment with new data sources or statistical methods will have access in a few clicks to easy-to-use, pre-configured data science environments, so that they can directly start to experiment. However, many users want to go deeper and build actual prototypes of production applications for their projects: configuring initialization scripts to tailor the environments to their needs, deploying an interactive app that delivers data visualization to users of their choice, deploying other services than those available in our catalogs, etc. For these advanced users to continue to push the boundaries of innovation, Onyxia gives them access to the underlying Kubernetes cluster. This means that users can freely open a terminal on an interactive service and interacts with the cluster - within the boundaries of their namespace - in order to apply custom resources and deploy custom applications or services.

Besides autonomy and scalability, the architectural choices of Onyxia also foster reproducibility of statistical computations. In the paradigm of containers, the user must learn to deal with resources which are by nature ephemeral, since they only exist at the time of their actual mobilization. This fosters the adoption of development best practices, notably the separation of the code — put on an internal or open-source forge such as GitLab or GitHub — the data — stored on a specific storage solution, such as MinIO — and the computing environment. While this requires an entry cost for users, it also helps them to conceive their projects as pipelines, i.e. a series of sequential steps with well-defined inputs and outputs (akin to directed acyclic graph (DAG)). The projects developed in that manner are usually more reproducible and portable — they can work seamlessly on different computing environments — and thus also more readily shareable with peers.

## An extensive catalogue of services to cover the entire lifecycle of data science projects {#sec-catalog}

In developing the Onyxia platform, our intention was to provide statisticians with a comprehensive environment designed to support end-to-end development of data science projects. As depicted in @fig-onyxia-catalog, the platform offers a vast array of services that span the complete lifecycle of a data science project.

![Onyxia's catalog aims at covering the entire lifecycle of data science projects](../../figures/onyxia-catalog.png){#fig-onyxia-catalog}

The primary usage of the platform is the deployment of interactive development environments (IDE), such as RStudio, Jupyter, or VSCode. These IDEs come equipped with the latest kernels of major open-source programming languages commonly employed by public statisticians (R, Python, Julia), as well as an extensive collection of packages commonly used in data science for each language. In order to ensure that services remain up-to-date and consistent between them, we maintain our own stack of underlying Docker images and rebuild it weekly. The stack of images is fully open-source[^images-datascience] and can thus be reused outside Onyxia.


As discussed in previous sections, the persistence layer of these interactive environments is mainly carried out by MinIO, Onyxia's default object storage solution. As it is based on a standardized REST API, files can be easily queried directly from R or Python using high-level packages. This in itself is an important step of ensuring reproducibility: the input files of a project are not mounted manually and then specified via paths adherent to a specific infrastructure and filesystem. Rather, files are specified as HTTP queries, making the overall structure of projects much more extendable. In our experience, the object-storage paradigm covers very well the needs of most statistical projects we accompany. However, additional database services such as PostgreSQL and MongoDB are available for applications with specific needs, such as those requiring online transaction processing (OLTP) capabilities or document-oriented storage.

As Onyxia was developed to allow experimentation with big data sources and machine learning methods, we also provide services optimized for scalability. For instance, frameworks like Spark and Trino that enable to perform distributed computations within Kubernetes. These services come pre-configured to integrate seamlessly with S3 storage, thus facilitating building integrated and efficient data pipelines.

Beyond mere experimentation, our goal is to empower statisticians to transition from trial phases to production-grade projects. In lines with principles from the DevOps approach, this involves facilitating the deployment of prototypes and their continuous improvement over time. To this end, we provide a set of open-source tools aimed at automatizing and industrializing the process of deploying data-intensive applications (ArgoCD, Argo-Workflows, MLflow). For projects leveraging machine-learning models, statisticians can serve their models through APIs, deploy them using the aforementioned tools, and manage their lifecycle using an API manager (e.g. Gravitee). [Section 4](../mlops/index.qmd#sec-mlops) will illustrate how these tools, particularly MLflow, have been central in putting machine learning models in production at Insee, in accordance with MLOps principles.

In @sec-principles-autonomy, we stressed that one of Onyxia's fundamental design principle was to avoid vendor lock-in. In line with this idea, organizations that implement Onyxia are free to customize catalogs to suit their specific requirements, or even opt to construct their own catalogs independent of Onyxia's default offerings. This flexibility ensures that organizations are not confined to a single solution or provider, and can adapt the platform to their evolving needs.

## Building commons: an open-source project and an open-innovation platform

As a fully open-source initiative, the Onyxia project aims at building "knowledge commons" by promoting and building software that can be easily reused in official statistics and beyond [@schweik2006free]. This concerns, first of all, the components on which Onyxia are based: both its constitutive technological bricks (Kubernetes, MinIO, Vault) as well as all the services from the catalog are open-source. But more crucially, all the code of the project is available openly on GitHub[^onyxia-github]. Alongside an in-depth documentation[^onyxia-docs], this greatly facilitates the potential for other organizations to create instances of data science platforms built upon the Onyxia software and tailor it to their respective needs (see @fig-onyxia-instances). This enabled the project to attract a growing community of contributors from official statistics (Statistics Norway), NGOs (Mercator Ocean), research centres and even industry, thus transitioning progressively towards a more decentralized governance of the project. In the next years, the involvement of NSIs from the European Statistical System is expected to increase as Onyxia was chosen as the reference data science platform in the context of the AIML4OS project, a "One-Stop-Shop" for Artificial Intelligence/Machine Learning for Official Statistics in the European Statistical System[^aiml4os].

[^onyxia-github]: [https://github.com/InseeFrLab/onyxia]()
[^onyxia-docs]: [https://docs.onyxia.sh/]()
[^aiml4os]: More information on this project available at [https://cros.ec.europa.eu/dashboard/aiml4os]()

![One project, multiple instances: the UI is adaptable to the graphic identity of the organization](../../figures/onyxia-instances.png){#fig-onyxia-instances}

Another major way in which we try to build commons is by developing and maintaining a showcase instance of the Onyxia project, the SSP Cloud [@comte2022sspcloud]. This platform, equipped with extensive and scalable computational resources[^cluster], is designed to be a sandbox for experimenting with cloud technologies and new data science methods. The full catalog of services of Onyxia is available on the platform, enabling motivated users to go beyond mere experimentation by producing "proof of concepts", with full autonomy regarding the configuration and orchestration of their services.

[^cluster]: On the physical side, the SSP Cloud consists in a Kubernetes cluster of about 20 servers, for a total capacity of 10 TB of RAM, 1100 CPUs, 34 GPUs and 150 TB of storage.

Beyond its technical capabilities, the SSP Cloud is an endeavour at embodying the principles of open-innovation [@chesbrough2003open]. Deployed on internet[^datalab], it is open not only to Insee employees, but also more broadly to French governmental agencies, French Universities and other European NSIs, and is dedicated to experimenting with data science methods using open data. Thus, the projects carried out on this platform showcase the growing abundance of datasets published openly by organizations. The fundamentally collaborative nature of the SSP Cloud has proven especially beneficial for organizing innovative events such as hackathons — both at the national and international levels — and in the academic sphere. It has become an integral resource for several universities and Grandes Ecoles in France, fostering the use of cloud-native and reproducible environments, and preventing vendor lock-in effect due to the over-reliance of educational organizations on proprietary cloud solutions. As a result, the platform is now widely used in the French National Statistical System and beyond, with about 800 unique users per month in 2024. These users form a dynamic community thanks to a centralized discussion canal; they help improve the user experience by reporting bugs, suggesting new features, and thus contribute directly to the project.

[^datalab]: [https://datalab.sspcloud.fr/]()


:::


<!-- ############################################################################################################## -->
<!-- ############################################################################################################## -->
<!-- ############################################################################################################## -->



::: {.content-visible when-profile="fr"}

# Onyxia : un projet open source pour construire des plateformes de datascience sur des technologies cloud{#sec-implementation-fr}

Cette section examine comment Onyxia, un projet open source initié par l’Insee, démocratise l’accès aux technologies *cloud* pour les statisticiens en fournissant des environnements modernes de *datascience* favorisant l’autonomie. Nous analysons comment cette initiative s’inscrit dans l’objectif général de création des "connaissances communes" en promouvant et en développant des logiciels facilement réutilisables dans le domaine des statistiques publiques et ailleurs.

## Rendre les technologies cloud accessibles aux statisticiens

Notre veille technologique et notre revue de la littérature ont mis en évidence les technologies *cloud*, en particulier la conteneurisation et le stockage d’objets, comme des éléments clés pour construire une plateforme de *datascience* à la fois scalable et flexible. En nous appuyant sur ces enseignements, nous avons mis en place notre premier cluster Kubernetes dans les locaux de l'Insee en 2020, en l’intégrant avec MinIO, un système de stockage d’objets *open source* conçu pour fonctionner de manière fluide avec Kubernetes. Cependant, nos premières expérimentations ont révélé un obstacle majeur à l’adoption généralisée des technologies *cloud* : la complexité de leur intégration. C’est une considération importante lorsqu’il s’agit de construire des architectures de données qui privilégient la modularité — une caractéristique essentielle pour atteindre la flexibilité que nous visons[^flexibilité]. Toutefois, la modularité des composants architecturaux implique également que toute application de données lancée sur le cluster doit être configurée pour communiquer avec tous les autres composants. Par exemple, dans un environnement *big data*, la configuration de Spark pour fonctionner sur Kubernetes tout en interagissant avec des ensembles de données stockés dans MinIO nécessite de nombreuses et complexes configurations (définition des points d'entrée, des jetons d’accès, etc.), une compétence qui dépasse généralement l’expertise des statisticiens.


[^flexibilité]: A telling example of the importance of building a modular architecture is the ability to switch between storage sources (on-premise, public cloud provider, etc.). The storage solution we chose, MinIO, is compatible with Amazon's S3 API, which has become a de facto standard in the cloud ecosystem due to the success of Amazon's AWS S3 storage solution. As a result, organizations that choose to use Onyxia are not tied to a specific storage solution: they can choose any solution that complies with the standards defined by the S3 API.


For instance, due to MinIO's compatibility with the Amazon S3 API, the storage source could easily be switched to one managed by another public cloud provider, without requiring substantial modifications.

This insight is really the base of the Onyxia project: choosing technologies that foster autonomy will not actually foster autonomy if their complexity acts as a barrier from widespread adoption in the organization. In recent years, statisticians at Insee already needed to adapt to a changing environment in terms of their everyday tools: transitioning from proprietary software (SAS®) to open-source ones (R, Python), acculturating to technologies that improve reproducibility (version control with Git), consuming and developing APIs, etc. These changes, making their job more and more akin to the one of software developers, already imply significant training and changes in daily work practices. Against this background, adoption of cloud-technologies was utterly dependent on making them readily accessible.

![Onyxia is the technical binder between cloud-native modular components](../../figures/onyxia-components.png){#fig-onyxia-components}


To bridge this gap, we developed Onyxia, an application that essentially acts as interface between the modular components that compose the architecture (see @fig-onyxia-components). The main entry point of the user is a user-friendly web application[^onyxia-ui]  that enables users to launch services from a data science catalog (see @sec-catalog) as running containers on the underlying Kubernetes cluster. The interface between the UI and Kubernetes is done by a lightweight custom API[^onyxia-api], that essentially transforms the application request of the user into a set of manifests to deploy Kubernetes resources. For a given application, these resources are packaged under the form of Helm charts, a popular way of packaging potentially complex applications on Kubernetes [@gokhale2021creating]. Although users can configure a service to tailor it to their needs, they will most of the time just launch an out-of-the-box service with default settings and start developing straight away. This point really illustrates the added value of Onyxia in facilitating the adoption of cloud technologies. By injecting authentication information and configuration into the containers at the initialization, we ensure that users can launch and manage data science services in which they can interact seamlessly with the data from their bucket on MinIO, their sensitive information (tokens, passwords) in a secret management tool such as Vault, etc. This automatic injection, coupled with the pre-configuration of data science environments in Onyxia's catalogs of images[^images-datascience] and associated helm-charts[^helm-charts-interactive-services], make it possible for users to execute potentially complex workloads — such as running distributed computations with Spark on Kubernetes using data stored in S3, or training deep-learning models using a GPU — without getting bogged down by the technicalities of configuration.

[^onyxia-ui]: [https://github.com/InseeFrLab/onyxia-ui]()
[^onyxia-api]: [https://github.com/InseeFrLab/onyxia-api]()
[^images-datascience]: [https://github.com/InseeFrLab/images-datascience]()
[^helm-charts-interactive-services]: [https://github.com/InseeFrLab/helm-charts-interactive-services]()

## Architectural choices aimed at fostering autonomy {#sec-principles-autonomy}

The Onyxia project is based on a few structuring principles, with a central theme: fostering autonomy, both at the organizational and individual levels. First, at the level of the organization by preventing vendor lock-in. In order to get a competitive edge, many commercial cloud providers develop applications and protocols that customers need to use to access cloud resources, but that are not interoperable, greatly complexifying potential migrations to another cloud platform [@opara2016critical]. Recognizing these challenges, there is a trend towards endorsing cloud-neutral strategies [@opara2017holistic] in order to reduce reliance on a single vendor’s specific solutions. In contrast, the use of Onyxia is inherently not restrictive: when an organization chooses to use it, it chooses the underlying technologies — containerization and object storage — but not the solution. The platform can be deployed on any Kubernetes cluster, either on-premise or in public clouds. Similarly, Onyxia was designed to be used with MinIO because it is an open-source object-storage solution, but is also compatible with objects storage solutions from various cloud providers (AWS, GCP).

Onyxia also fosters autonomy at the level of users. Proprietary softwares that have been used intensively in official statistics — such as SAS or STATA — also produce a vendor lock-in phenomenon. The costs of licensing are high and can evolve quickly, and users are tied in certain ways of performing computations, preventing progressive upskilling. On the contrary, Onyxia aspires to be removable; we want to enhance users' familiarity and comfort with the underlying cloud technologies rather than act as a permanent fixture in their workflow. An illustrative example of this philosophy is the platform's approach to user actions: for tasks performed through the UI, such as launching a service or managing data, we provide users with the equivalent terminal commands, promoting a deeper understanding of what actually happens on the infrastructure when triggering something. Furthermore, all the services offered through Onyxia's catalog are open-source.

![Launching a service through Onyxia's UI.](../../figures/service-configuration.png){#fig-service-configuration}

Note: Services from Onyxia's catalog can either be used vanilla or configured by the users to tailor them to their specific needs. In order to limit the dependence of users on Onyxia, each action performed by the user on the UI is accompanied by the actual command that is executed on the Kubernetes cluster.


Naturally, the way Onyxia makes statisticians more autonomous in their work depends on their needs and familiarity with IT skills. Statisticians that just want to have access to extensive computational resources to experiment with new data sources or statistical methods will have access in a few clicks to easy-to-use, pre-configured data science environments, so that they can directly start to experiment. However, many users want to go deeper and build actual prototypes of production applications for their projects: configuring initialization scripts to tailor the environments to their needs, deploying an interactive app that delivers data visualization to users of their choice, deploying other services than those available in our catalogs, etc. For these advanced users to continue to push the boundaries of innovation, Onyxia gives them access to the underlying Kubernetes cluster. This means that users can freely open a terminal on an interactive service and interacts with the cluster - within the boundaries of their namespace - in order to apply custom resources and deploy custom applications or services.

Besides autonomy and scalability, the architectural choices of Onyxia also foster reproducibility of statistical computations. In the paradigm of containers, the user must learn to deal with resources which are by nature ephemeral, since they only exist at the time of their actual mobilization. This fosters the adoption of development best practices, notably the separation of the code — put on an internal or open-source forge such as GitLab or GitHub — the data — stored on a specific storage solution, such as MinIO — and the computing environment. While this requires an entry cost for users, it also helps them to conceive their projects as pipelines, i.e. a series of sequential steps with well-defined inputs and outputs (akin to directed acyclic graph (DAG)). The projects developed in that manner are usually more reproducible and portable — they can work seamlessly on different computing environments — and thus also more readily shareable with peers.

## An extensive catalogue of services to cover the entire lifecycle of data science projects {#sec-catalog}

In developing the Onyxia platform, our intention was to provide statisticians with a comprehensive environment designed to support end-to-end development of data science projects. As depicted in @fig-onyxia-catalog, the platform offers a vast array of services that span the complete lifecycle of a data science project.

![Onyxia's catalog aims at covering the entire lifecycle of data science projects](../../figures/onyxia-catalog.png){#fig-onyxia-catalog}

The primary usage of the platform is the deployment of interactive development environments (IDE), such as RStudio, Jupyter, or VSCode. These IDEs come equipped with the latest kernels of major open-source programming languages commonly employed by public statisticians (R, Python, Julia), as well as an extensive collection of packages commonly used in data science for each language. In order to ensure that services remain up-to-date and consistent between them, we maintain our own stack of underlying Docker images and rebuild it weekly. The stack of images is fully open-source[^images-datascience] and can thus be reused outside Onyxia.


As discussed in previous sections, the persistence layer of these interactive environments is mainly carried out by MinIO, Onyxia's default object storage solution. As it is based on a standardized REST API, files can be easily queried directly from R or Python using high-level packages. This in itself is an important step of ensuring reproducibility: the input files of a project are not mounted manually and then specified via paths adherent to a specific infrastructure and filesystem. Rather, files are specified as HTTP queries, making the overall structure of projects much more extendable. In our experience, the object-storage paradigm covers very well the needs of most statistical projects we accompany. However, additional database services such as PostgreSQL and MongoDB are available for applications with specific needs, such as those requiring online transaction processing (OLTP) capabilities or document-oriented storage.

As Onyxia was developed to allow experimentation with big data sources and machine learning methods, we also provide services optimized for scalability. For instance, frameworks like Spark and Trino that enable to perform distributed computations within Kubernetes. These services come pre-configured to integrate seamlessly with S3 storage, thus facilitating building integrated and efficient data pipelines.

Beyond mere experimentation, our goal is to empower statisticians to transition from trial phases to production-grade projects. In lines with principles from the DevOps approach, this involves facilitating the deployment of prototypes and their continuous improvement over time. To this end, we provide a set of open-source tools aimed at automatizing and industrializing the process of deploying data-intensive applications (ArgoCD, Argo-Workflows, MLflow). For projects leveraging machine-learning models, statisticians can serve their models through APIs, deploy them using the aforementioned tools, and manage their lifecycle using an API manager (e.g. Gravitee). [Section 4](../mlops/index.qmd#sec-mlops) will illustrate how these tools, particularly MLflow, have been central in putting machine learning models in production at Insee, in accordance with MLOps principles.

In @sec-principles-autonomy, we stressed that one of Onyxia's fundamental design principle was to avoid vendor lock-in. In line with this idea, organizations that implement Onyxia are free to customize catalogs to suit their specific requirements, or even opt to construct their own catalogs independent of Onyxia's default offerings. This flexibility ensures that organizations are not confined to a single solution or provider, and can adapt the platform to their evolving needs.

## Building commons: an open-source project and an open-innovation platform

As a fully open-source initiative, the Onyxia project aims at building "knowledge commons" by promoting and building software that can be easily reused in official statistics and beyond [@schweik2006free]. This concerns, first of all, the components on which Onyxia are based: both its constitutive technological bricks (Kubernetes, MinIO, Vault) as well as all the services from the catalog are open-source. But more crucially, all the code of the project is available openly on GitHub[^onyxia-github]. Alongside an in-depth documentation[^onyxia-docs], this greatly facilitates the potential for other organizations to create instances of data science platforms built upon the Onyxia software and tailor it to their respective needs (see @fig-onyxia-instances). This enabled the project to attract a growing community of contributors from official statistics (Statistics Norway), NGOs (Mercator Ocean), research centres and even industry, thus transitioning progressively towards a more decentralized governance of the project. In the next years, the involvement of NSIs from the European Statistical System is expected to increase as Onyxia was chosen as the reference data science platform in the context of the AIML4OS project, a "One-Stop-Shop" for Artificial Intelligence/Machine Learning for Official Statistics in the European Statistical System[^aiml4os].

[^onyxia-github]: [https://github.com/InseeFrLab/onyxia]()
[^onyxia-docs]: [https://docs.onyxia.sh/]()
[^aiml4os]: More information on this project available at [https://cros.ec.europa.eu/dashboard/aiml4os]()

![One project, multiple instances: the UI is adaptable to the graphic identity of the organization](../../figures/onyxia-instances.png){#fig-onyxia-instances}

Another major way in which we try to build commons is by developing and maintaining a showcase instance of the Onyxia project, the SSP Cloud [@comte2022sspcloud]. This platform, equipped with extensive and scalable computational resources[^cluster], is designed to be a sandbox for experimenting with cloud technologies and new data science methods. The full catalog of services of Onyxia is available on the platform, enabling motivated users to go beyond mere experimentation by producing "proof of concepts", with full autonomy regarding the configuration and orchestration of their services.

[^cluster]: On the physical side, the SSP Cloud consists in a Kubernetes cluster of about 20 servers, for a total capacity of 10 TB of RAM, 1100 CPUs, 34 GPUs and 150 TB of storage.

Beyond its technical capabilities, the SSP Cloud is an endeavour at embodying the principles of open-innovation [@chesbrough2003open]. Deployed on internet[^datalab], it is open not only to Insee employees, but also more broadly to French governmental agencies, French Universities and other European NSIs, and is dedicated to experimenting with data science methods using open data. Thus, the projects carried out on this platform showcase the growing abundance of datasets published openly by organizations. The fundamentally collaborative nature of the SSP Cloud has proven especially beneficial for organizing innovative events such as hackathons — both at the national and international levels — and in the academic sphere. It has become an integral resource for several universities and Grandes Ecoles in France, fostering the use of cloud-native and reproducible environments, and preventing vendor lock-in effect due to the over-reliance of educational organizations on proprietary cloud solutions. As a result, the platform is now widely used in the French National Statistical System and beyond, with about 800 unique users per month in 2024. These users form a dynamic community thanks to a centralized discussion canal; they help improve the user experience by reporting bugs, suggesting new features, and thus contribute directly to the project.

[^datalab]: [https://datalab.sspcloud.fr/]()


::: 