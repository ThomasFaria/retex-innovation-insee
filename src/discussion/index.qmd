---
number-offset: 4
---

::: {.content-visible when-profile="en"}

# Discussion

The development of data science methods offers considerable potential for official statistics. However, our ability to create value from these new methods essentially depends on our capacity to produce production-grade systems that serve their purpose in a robust way. This evolution calls for deep reflection on what constitutes a modern, scalable data science infrastructure for official statistics. This article presents the Onyxia project, the proposal for such a platform that we are developing at Insee. By exploiting cloud-native technologies that have become standards in the data eco-system, it aims to increase statisticians' autonomy in the orchestration of their statistical treatments, while promoting reproducibility of produced statistics. As cloud technologies are notoriously difficult to configure, the core value of Onyxia's lies in making them accessible to statisticians via a user-friendly interface and a catalog of pre-configured services to cover most common uses. Through an internal project aiming at revising the NACE classification process using machine learning methods, we illustrate how Onyxia enables to iteratively build production-grade machine learning projects that promote continuous improvement, a fundamental principle of the MLOps approach.

Initially developed as an internal project, Onyxia has gained recognition beyond the scope of Insee or the French administration. Convinced of the potential of cloud technologies to foster autonomy and leverage the full potential of data science, several organizations now have a production instance of Onyxia running, and multiple others are in the process of either testing or implementing one. Besides, the choice of Onyxia as the reference data science platform in the context of the AIML4OS project should further facilitate its adoption within the ESS. This trend is naturally very beneficial to the Onyxia project, as it moves from a project developed in open-source — but mainly at Insee — to a full open-source project with a growing base of contributors. This in turn facilitates its adoption by other organizations, since it gives more guarantees on its sustainability independently of Insee's strategy. The governance of the project is currently evolving to reflect this trend. For instance with the organization of monthly community calls and the creation of a public channel and roadmap for the project[^onyxia-project].

[^onyxia-project]: All information are available on the GitHub depository of the project: [https://github.com/InseeFrLab/onyxia]()

Despite this success, we observe several limitations to the widespread adoption of the project in organizations. First, it is essential to remind that the fundamental choice made by organizations that adopt Onyxia is not the software itself, but the underlying technologies: containerization (through Kubernetes) and object storage. These technologies can represent substantial entry costs for organizations, as they demand a significant commitment to developing and maintaining skills which are not readily found in NSOs. Yet, the general trend towards cloud-native solutions among data-centric organizations suggests a favourable shift that could mitigate these challenges over time.

Similarly, the transition towards cloud-native technologies induces entry costs for statisticians. First, they often deal with a loss of references regarding where computations actually happen: while they may be accustomed to performing computation on centralized servers rather than a personal computer, the container adds a layer of abstraction that make the location hard to grasp at first. But the major perceived change in this paradigm is the loss of data persistence. In traditional setups — either a personal computer or a server accessed through a virtual desktop — the code, the data and the computing environment are kind of mixed in a black box fashion. On the contrary, containers have no persistence by design. While object storage provides this persistence, a proper use of these infrastructures for statistical projects require a variety of tools and corresponding skills: using a version control system for the code, interacting with the object storage API to store the data, providing configuration files or secrets as inputs, etc. In a way, these entry costs can be seen as the "price" of autonomy: thanks to cloud-native technologies, statisticians now have access to scalable and flexible environments that enable them to experiment more freely, but this autonomy requires a significant skills upgrade which may be overwhelming at first and limit adoption. However, our experience at Insee suggests that this effect can largely be mitigated through a combination of training statisticians to development best practices and accompanying statistical projects when transitioning to cloud infrastructures.

While Onyxia has significantly democratized access to cloud-native technologies for statisticians, the actual integration of data science methods in the statistical production of NSOs encompasses broader challenges, organizational in nature. A major hindsight from the deployment of our first ML model in production is the necessity to overcome skill compartmentalization across IT, business, and innovation teams. By nature, production-grade ML projects involve a wide range of skills — knowledge of the business domain, model training and fine-tuning, deployment and monitoring — and thus effective collaboration between professionals with different work cultures, programming languages, etc. Our experience shows that cloud technologies, by fostering autonomy of data scientists, give more continuity to ML projects and facilitate this much needed collaboration between various profiles. However, fully addressing these challenges involve measures that go beyond the technical domain. For instance, embedding some data science capabilities directly within business teams, in complement of centralized innovation teams, could foster better alignment with project objectives. Also, recruiting profiles that are not typically present in NSOs, such as data engineers or ML engineers, could bring new essential skills that lie at the intersection of statistical methodology and computer techniques. Ultimately, the transition towards a data science-driven approach in statistical production should rely on a balanced strategy that couples technical solutions such as Onyxia with comprehensive organizational adjustments, fostering a culture of collaboration, continuous learning, and innovation.


:::


<!-- ############################################################################################################## -->
<!-- ############################################################################################################## -->
<!-- ############################################################################################################## -->



::: {.content-visible when-profile="fr"}

# Discussion


Le développement des méthodes de *data science* offre un potentiel considérable pour la statistique publique. Cependant, notre capacité à tirer profit de ces nouvelles méthodes dépend essentiellement de notre aptitude à produire des chaînes de production de qualité, robustes et adaptés à leurs objectifs. Cette évolution nécessite une réflexion approfondie sur ce qui constitue une infrastructure moderne et évolutive pour la *data science* dans le domaine des statistiques publiques. Cet article présente le projet Onyxia, une proposition pour une telle plateforme développée à l'Insee. En exploitant des technologies *cloud* devenues des standards dans l'écosystème de la donnée, le projet vise à accroître l'autonomie des statisticiens dans l'orchestration de leurs traitements statistiques, tout en favorisant la reproductibilité des statistiques produites. Les technologies *cloud* étant notoirement difficiles à configurer, la valeur principale d’Onyxia réside dans leur accessibilité pour les statisticiens grâce à une interface ergonomique, simple d'utilisation, et un catalogue de services préconfigurés couvrant les usages les plus courants d'un statisticien public. À travers un projet interne visant à refondre le processus de codification de l'Activité Principale de l'Entreprise (APE) en utilisant des méthodes d'apprentissage automatique, nous illustrons comment Onyxia permet de construire de manière itérative des projets de *machine learning* prêts à passer en production, favorisant l'amélioration continue, un principe fondamental de l'approche MLOps.

Initialement développé comme un projet interne, Onyxia a acquis une reconnaissance dépassant le cadre de l'Insee ou de l'administration française. Convaincues du potentiel des technologies *cloud* pour renforcer l'autonomie et exploiter pleinement le potentiel de la *data science*, plusieurs organisations disposent désormais d'une instance de production d'Onyxia (comme c'est le cas à l'Insee avec le déploiement récent de $LS^3$), et de nombreuses autres sont en phase de test ou d'implémentation. Par ailleurs, le choix d’Onyxia comme plateforme de *data science* de référence dans le cadre du projet AIML4OS devrait encore accroître son adoption au sein du SSE. Cette tendance est naturellement très bénéfique pour le projet Onyxia, qui passe d’un projet développé en *open source* — mais principalement à l’Insee — à un véritable projet *open source* avec une base croissante de contributeurs. Cela, en retour, facilite son adoption par d'autres organisations, en offrant davantage de garanties sur sa pérennité indépendamment de la stratégie de l'Insee. La gouvernance du projet évolue actuellement pour refléter cette tendance, notamment avec l'organisation de réunions communautaires mensuelles et la création d’un canal public et d’une feuille de route pour le projet[^onyxia-project].

[^onyxia-project]: Toutes les informations sont disponibles sur le dépôt GitHub du projet : [https://github.com/InseeFrLab/onyxia]()

Malgré ce succès, nous constatons plusieurs limites à l'adoption généralisée du projet au sein des organisations. Tout d'abord, il est essentiel de rappeler que le choix fondamental fait par les organisations qui adoptent Onyxia ne porte pas sur le logiciel en lui-même, mais sur les technologies sous-jacentes : la conteneurisation (via Kubernetes) et le stockage d'objets. Ces technologies peuvent représenter des coûts d'entrée important pour les organisations, puisqu'elles nécessitent un investissement dans le développement et le maintien de compétences qui ne sont pas toujours présentes dans les INS. Cependant, on constate que les organisations qui manipulent de la donnée tendent de plus en plus à s'orienter vers des solutions *cloud* qui pourrait atténuer ces défis à long terme.

De même, la transition vers les technologies *cloud* impose des coûts d'entrée pour les statisticiens. Tout d'abord, ils sont souvent confrontés à une perte de repères quant à l'endroit où les calculs sont réellement effectués : bien qu'ils soient habitués à effectuer des calculs sur des serveurs centralisés plutôt que sur un ordinateur personnel, le conteneur ajoute une couche d'abstraction qui rend cet emplacement difficile à appréhender au départ. Mais le changement le plus pertubant dans ce paradigme est la perte de persistance des données. Dans les configurations traditionnelles — qu'il s'agisse d'un ordinateur personnel ou d'un serveur accessible via un bureau virtuel — le code, les données et l'environnement de calcul sont souvent mélangés dans une sorte de boîte noire. À l'inverse, les conteneurs, par construction, n'ont pas de persistance. Si le stockage d'objets fournit cette persistance, une utilisation adéquate de ces infrastructures  exige une variété d'outils et de compétences : utilisation d'un système de contrôle de version pour le code (e.g. Git), interaction avec l'API de stockage d'objets pour enregistrer les données, gestion de fichiers de configuration et/ou de secrets et variables d'environnement, etc. En un sens, ces coûts d'entrée peuvent être considérés comme le « prix » de l'autonomie : grâce aux technologies *cloud*, les statisticiens ont désormais accès à des environnements évolutifs et flexibles leur permettant d’expérimenter plus librement, mais cette autonomie exige une montée en compétences significative, qui peut être intimidante et, *in fine*, limiter cette adoption. Cependant, notre expérience à l'Insee montre que cet effet peut être largement atténué grâce à une combinaison de formation des statisticiens aux bonnes pratiques de développement et d’accompagnement des projets statistiques lors de leur transition vers des infrastructures *cloud*.

Bien qu'Onyxia ait significativement démocratisé l'accès aux technologies *cloud* pour les statisticiens, l'intégration effective des méthodes de *data science* dans la production statistique des INS soulève des défis plus larges, d'ordre organisationnel. Une leçon majeure tirée du déploiement de notre premier modèle de *machine learning* en production est la nécessité de surmonter la segmentation des compétences entre les équipes informatiques, métier et innovation. Par nature, les projets de *machine learning*, pour pouvoir passer en production, impliquent un large éventail de compétences — connaissance du domaine métier, entraînement et amélioration des modèles ainsi que leur déploiement et supervision — et nécessitent donc une collaboration efficace entre des professionnels aux cultures de travail et langages de programmation variés. Notre expérience montre que les technologies *cloud*, en favorisant l'autonomie des *data scientists*, apportent plus de continuité aux projets d'apprentissage automatique et facilitent cette collaboration essentielle entre les différents profils. Toutefois, répondre pleinement à ces défis nécessite des choix qui dépassent le domaine technique. Par exemple, intégrer certaines compétence en *data science* directement au sein des équipes métier, en complément des équipes d'innovation centralisées, pourrait favoriser une meilleure collaboration. De même, recruter des profils qui ne sont pas traditionnellement présents dans les INS, comme les *data engineers* ou les *ML engineers*, pourrait apporter de nouvelles compétences à l'intersection des méthodologies statistiques et des techniques informatiques. Au final, la transition vers une approche axée sur la *data science* dans la production statistique doit s'appuyer sur une stratégie équilibrée qui lie des solutions techniques comme Onyxia avec des ajustements organisationnels et humains, favorisant une culture de collaboration, de formation continue et d’innovation.


::: 

