\section{Discussion}

\subsection{Future}

\begin{itemize}
    \item Onyxia, un bien commun opensource largement réutilisé (Insee, SSB) $\rightarrow$ faciliter les contributions pour la postérité du projet open-source, qui dépasse l'Insee
    \item One-stop-shop : SSP Cloud comme plateforme de référence pour les projets de ML $\rightarrow$ croissance de l'offre de formation (+ traduction)
    \item Accompagner les réinstanciations (datafid, POCs dans le secteur privé)
    \item Multiplication des projets qui passent en prod (applications de dataviz, modèles de ML avec MLOps, webscraping : Jocas/WINs)
\end{itemize}

\subsection{Discussion}

\begin{itemize}
    \item Cout d'entrée important pour l'organisation : stockage objet, cluster kube/conteneurisation
    \begin{itemize}
        \item Choix fondamental d'archi $\rightarrow$ limite à la diffusion d'onyxia
        \item Assumer le choix : compétences, organisation~...
        \item Mais globalement : tendance favorable car beaucoup d'orga et INS font ce choix
    \end{itemize}
    \item Cout d'entrée important pour le statisticien :
    \begin{itemize}
        \item Non-persistence de l'environnement $\rightarrow$ git + stockage objet
        \item Travail dans un conteneur $\rightarrow$ perte de repères sur l'environnement
        \item Mais formation : bonnes pratiques + écoles de formation Insee + accompagnements
    \end{itemize}
    \item SSP Cloud :
    \begin{itemize}
        \item Instance ouverte $\rightarrow$ absence de données sensibles $\rightarrow$ grosse limitation des cas d'usage réalisables + frustrations $\rightarrow$ en résumé, difficile de maximiser à la fois innovation et sécurité (pb sur-contraint)
        \item $\rightarrow$ résolution via le choix de l'innovation max car sujet des échanges inter-administration de données complexe + le SSP Cloud a pavé la voie à des instances internes, plus fermées $\rightarrow$ stratégie assumée "platform-as-a-package" : projet open-source packagé $\rightarrow$ facilité ++ de réinstanciation
        \item Pas une plateforme de diffusion de données $\rightarrow$ pas de stratégie globale de gouvernance $\rightarrow$ le sujet de la méta-donnée n'est pas abordé.
    \end{itemize}
    \item Gouvernance :
    \begin{itemize}
        \item Quelle organisation ? Equipe DS centralisée qui vient en appui ou data scientists dans les orgas métiers ? Collaboration avec les équipes infos ? (cf. graphique orga/compétences de Romain)
    \end{itemize}
\end{itemize}


\subsubsection{Governance and collaboration challenges in ML Projects}

During the deployment of our first model into production, we encountered several governance challenges that we had not anticipated. As explained in Section \ref{sec:mlops}, we initiated the project with three distinct teams: an IT team comprised of developers, the core business team responsible for maintaining the Sirene directory, and finally, the innovation team consisting of data scientists and data engineers. The creation of the SSP Lab\footnote{Name of the innovation team.} at Insee in 2018 was justified to support the business teams on projects with relatively precise objectives in terms of statistical production and to experimentally introduce new methods into the statistical process, including machine learning methods. Initially, the innovation team's sole objective was to conduct an experiment and let the business team judge its relevance based on the results obtained. However, due to the urgency and quality of the results, the innovation team continued to collaborate with the business team to assist in production deployment.

This phase highlighted several issues, with the primary one being the compartmentalization of skills. The innovation team had limited knowledge of business issues and was unable to make certain decisions independently. The business team, on the other hand, had very few data science skills and was unable to manage the production deployment of the experiment alone. Finally, the IT team, although well-versed in DevOps best practices, had no knowledge of MLOps approach and of the methodological tools used in machine learning. Additionally, the programming languages used by the production and innovation teams were different, which have slowed down the model's production deployment. Before using MLflow and its Model Registry functionality, the preprocessing done in Python had to be reprogrammed in Java, which proved to be very tedious. We realized how code duplication was a source of errors and needed to be avoided as much as possible.

To address these challenges, several measures were implemented at Insee. Firstly, a data scientist was hired in September 2023 and integrated into the business team to take responsibility for the model in production, its monitoring, and retraining. The goal is to have someone who fully understands the business issues to quickly integrate new features as needed. Furthermore, to anticipate the arrival of multiple machine learning models in production, a Python training plan for developers was launched to enhance their skills with open-source software and align development and production languages.


parler de limportance de la communication avec les gestionnaire pour la confiance
